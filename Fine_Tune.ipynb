{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "171513d4-fef2-4e80-af98-654b3f88b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "device = torch.device(\"cuda\")\n",
    "df = pd.read_csv(\"Merged_Emotions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67a42a70-e1b4-49e6-8756-69d70e0c5e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71                              Sigh Martinez... but lol.\n",
       "1002    u/alexinup and u/PSGAcademy competing in a WC ...\n",
       "2023    If you beat Italy, Croatia, Germany, France an...\n",
       "2069    Kane is non existent, walker too sloppy, Belli...\n",
       "4100    ngl Bissouma getting a yellow  seconds into th...\n",
       "                              ...                        \n",
       "582                                    Mbappe with Adidas\n",
       "1520                    So fucking happy that france lost\n",
       "5810    Not to bat for Madrid here, but that's rich co...\n",
       "3659    Disappointed, but given how badly we played ea...\n",
       "2238            Should've started with Palmer and Watkins\n",
       "Name: text, Length: 4603, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column Match_cat\n",
    "df['Match_cat'] = df['Match'].map({'FIFA World Cup 2022': 1, 'UEFA European Championship 2024': 2, \n",
    "'Premier League 2024': 3, 'Champions League 2024': 4})\n",
    "df.tail()\n",
    "\n",
    "# Split csv\n",
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['Match_cat'],  \n",
    "                                                                    random_state = 2024,  \n",
    "                                                                    test_size = 0.3,  \n",
    "                                                                    stratify = df['Match_cat']) \n",
    "  \n",
    "  \n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,  \n",
    "                                                                random_state = 2024,  \n",
    "                                                                test_size = 0.5,  \n",
    "                                                                stratify = temp_labels)\n",
    "\n",
    "train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f4f4ddb-0423-42c7-a2b0-f5cc0fbd9a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-original\", from_pt = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b241538-e07c-43d2-9011-e103c1729dec",
   "metadata": {},
   "source": [
    "# Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "747b49c5-f41c-4181-b145-eceeadd79198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.329e+03, 2.050e+02, 4.900e+01, 1.500e+01, 3.000e+00, 1.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([  1. ,  49.3,  97.6, 145.9, 194.2, 242.5, 290.8, 339.1, 387.4,\n",
       "        435.7, 484. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_lens = [str(i).split() for i in train_text]\n",
    "train_lens = [len(i) for i in train_lens]\n",
    "plt.hist(train_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34abb30c-d72d-4224-8272-64e1918cbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most comments have around 25 words so padding length = 25\n",
    "pad_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80d8ff40-3af2-412e-ae83-05d2b9ceea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that inputs are lists of strings\n",
    "train_text = [str(item) if item is not None else '' for item in train_text]\n",
    "val_text = [str(item) if item is not None else '' for item in val_text]\n",
    "test_text = [str(item) if item is not None else '' for item in test_text]\n",
    "\n",
    "# Tokenize and encode sequences for training, validation, and testing\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text, \n",
    "    max_length=pad_len, \n",
    "    padding=True,  # Automatically pad to max_length\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text, \n",
    "    max_length=pad_len, \n",
    "    padding=True,  # Automatically pad to max_length\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text, \n",
    "    max_length=pad_len, \n",
    "    padding=True,  # Automatically pad to max_length\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# Convert tokenized outputs to tensors\n",
    "train_seq = torch.tensor(tokens_train['input_ids']) \n",
    "train_mask = torch.tensor(tokens_train['attention_mask']) \n",
    "train_y = torch.tensor(train_labels.tolist())  # Ensure train_labels is a list or tensor\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids']) \n",
    "val_mask = torch.tensor(tokens_val['attention_mask']) \n",
    "val_y = torch.tensor(val_labels.tolist())  # Ensure val_labels is a list or tensor\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids']) \n",
    "test_mask = torch.tensor(tokens_test['attention_mask']) \n",
    "test_y = torch.tensor(test_labels.tolist())  # Ensure test_labels is a list or tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc44e540-049b-4845-8285-1df81c0dd82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze the pretrained layers \n",
    "for param in model.trainable_variables: \n",
    "    param.requires_grad = False\n",
    "  \n",
    "#defining new layers \n",
    "class BERT_architecture(nn.Module): \n",
    "  \n",
    "    def __init__(self, bert): \n",
    "        \n",
    "      super(BERT_architecture, self).__init__() \n",
    "  \n",
    "      self.bert = bert  \n",
    "        \n",
    "      # dropout layer \n",
    "      self.dropout = nn.Dropout(0.2) \n",
    "        \n",
    "      # relu activation function \n",
    "      self.relu =  nn.ReLU() \n",
    "  \n",
    "      # dense layer 1 \n",
    "      self.fc1 = nn.Linear(768,512) \n",
    "        \n",
    "      # dense layer 2 (Output layer) \n",
    "      self.fc2 = nn.Linear(512,2) \n",
    "  \n",
    "      #softmax activation function \n",
    "      self.softmax = nn.LogSoftmax(dim=1) \n",
    "  \n",
    "    #define the forward pass \n",
    "    def forward(self, sent_id, mask): \n",
    "  \n",
    "      #pass the inputs to the model   \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False) \n",
    "        \n",
    "      x = self.fc1(cls_hs) \n",
    "  \n",
    "      x = self.relu(x) \n",
    "  \n",
    "      x = self.dropout(x) \n",
    "  \n",
    "      # output layer \n",
    "      x = self.fc2(x) \n",
    "        \n",
    "      # apply softmax activation \n",
    "      x = self.softmax(x) \n",
    "  \n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d94ab5ee-e07e-4d7b-88c7-ea2888a00d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 64\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f308c85d-1ac7-488b-9099-6788090ee4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "bert_model = BERT_architecture(model)\n",
    "\n",
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(bert_model.parameters(),lr = 1e-5)  # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "67dc8f5a-dbef-46a9-9ba0-0a739954edc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class weights are [0.82196429 0.83690909 2.14692164 0.89067337] for [1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight(class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_labels),\n",
    "                                        y = train_labels \n",
    "                                     )\n",
    "print(\"class weights are {} for {}\".format(class_weights,np.unique(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4dfe3f65-0e0d-434f-9ebf-d00a4d81552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  bert_model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7ff8aedf-45e5-4b02-921a-92bc81088a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  bert_model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # # Calculate elapsed time in minutes.\n",
    "      # elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5119d771-f667-462c-9690-c6e4aabbb10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 6\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, epochs))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#train model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m train_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#evaluate model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m valid_loss, _ \u001b[38;5;241m=\u001b[39m evaluate()\n",
      "Cell \u001b[0;32mIn[74], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  Batch \u001b[39m\u001b[38;5;132;01m{:>5,}\u001b[39;00m\u001b[38;5;124m  of  \u001b[39m\u001b[38;5;132;01m{:>5,}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(step, \u001b[38;5;28mlen\u001b[39m(train_dataloader)))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# push the batch to gpu\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     21\u001b[0m sent_id, mask, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# clear previously calculated gradients \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[74], line 19\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  Batch \u001b[39m\u001b[38;5;132;01m{:>5,}\u001b[39;00m\u001b[38;5;124m  of  \u001b[39m\u001b[38;5;132;01m{:>5,}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(step, \u001b[38;5;28mlen\u001b[39m(train_dataloader)))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# push the batch to gpu\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     21\u001b[0m sent_id, mask, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# clear previously calculated gradients \u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/cuda/__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "epochs = 6\n",
    "\n",
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print('\\nTraining Loss: {}'.format(train_loss))\n",
    "    print('Validation Loss: {}'.format(valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e2b34fc-778d-41fc-a8b6-a8f5fd5f63f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# get predictions for test data \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(): \n\u001b[0;32m----> 3\u001b[0m   preds \u001b[38;5;241m=\u001b[39m model(\u001b[43mtest_seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, test_mask\u001b[38;5;241m.\u001b[39mto(device)) \n\u001b[1;32m      4\u001b[0m   preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report \n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/cuda/__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# get predictions for test data \n",
    "with torch.no_grad(): \n",
    "  preds = model(test_seq.to(device), test_mask.to(device)) \n",
    "  preds = preds.detach().cpu().numpy() \n",
    "    \n",
    "from sklearn.metrics import classification_report \n",
    "pred = np.argmax(preds, axis = 1) \n",
    "print(classification_report(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1feb8-e797-472d-9a79-2a85ef5b10ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
